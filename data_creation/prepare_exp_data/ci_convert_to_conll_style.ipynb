{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "collapsed": true,
    "pycharm": {
     "name": "#%%\n"
    }
   },
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": 1,
   "outputs": [
    {
     "data": {
      "text/plain": "'\\nIn this script, we want to convert annotations to conll style. There are several steps:\\n1.clustering input data\\n2.Turn cluster data into conll format\\n3.Try to run the preprocess script from HOI code base\\n'"
     },
     "execution_count": 1,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "\"\"\"\n",
    "In this script, we want to convert annotations to conll style. There are several steps:\n",
    "1.clustering input data\n",
    "2.Turn cluster data into conll format\n",
    "3.Try to run the preprocess script from HOI code base\n",
    "\"\"\""
   ],
   "metadata": {
    "collapsed": false,
    "pycharm": {
     "name": "#%%\n"
    }
   }
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "outputs": [],
   "source": [
    "import pickle as pkl\n",
    "from copy import deepcopy\n",
    "import json\n",
    "import jsonlines\n",
    "import os\n",
    "import csv\n",
    "from utils.my_util import cluster_mentions, remove_speaker_prefix"
   ],
   "metadata": {
    "collapsed": false,
    "pycharm": {
     "name": "#%%\n"
    }
   }
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "outputs": [],
   "source": [],
   "metadata": {
    "collapsed": false,
    "pycharm": {
     "name": "#%%\n"
    }
   }
  },
  {
   "cell_type": "markdown",
   "source": [
    "## Load Source Friends Dataset"
   ],
   "metadata": {
    "collapsed": false,
    "pycharm": {
     "name": "#%% md\n"
    }
   }
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "outputs": [],
   "source": [
    "all_data = []\n",
    "\n",
    "root_path = 'data/raw_source/friends/'\n",
    "for i, file_name in enumerate(os.listdir(root_path)):\n",
    "    if file_name[-4:]!=\"json\":\n",
    "        continue\n",
    "    # if i!=0:\n",
    "    #     continue\n",
    "    with open(root_path+file_name, 'r') as f:\n",
    "        data = json.load(f)\n",
    "        season_id = data['season_id']\n",
    "        episodes = data['episodes']\n",
    "        for episode in episodes:\n",
    "            episode_id = episode['episode_id']\n",
    "            scenes = episode['scenes']\n",
    "            for scene in scenes:\n",
    "                temp_sentences = []\n",
    "                temp_answers = []\n",
    "                temp_speakers = []\n",
    "\n",
    "                scene_id = scene['scene_id']\n",
    "                utterances = scene['utterances']\n",
    "                # if scene_id != \"s01_e24_c01\":\n",
    "                #     continue\n",
    "                for utterance in utterances:\n",
    "                    utt_speaker = \" \".join(utterance['speakers'])\n",
    "                    tokens = utterance['tokens']\n",
    "                    if 'character_entities' not in utterance:\n",
    "                        continue\n",
    "                    character_entities = utterance['character_entities']\n",
    "\n",
    "                    # Collect mentions in multiple utterance\n",
    "                    utt_sentences = []\n",
    "                    utt_answers = []\n",
    "                    mention_dict = {}\n",
    "                    # print(utt_speaker)\n",
    "                    for sent, mentions in zip(tokens, character_entities):\n",
    "                        for mention in mentions:\n",
    "                            start = mention[0]+len(utt_sentences)\n",
    "                            end = mention[1]+len(utt_sentences)\n",
    "                            mention_name = \" \".join(mention[2:])\n",
    "                            utt_answers.append([len(temp_sentences), start, end, mention_name])\n",
    "                        utt_sentences.extend(sent)\n",
    "\n",
    "                    if not utt_sentences:\n",
    "                        continue\n",
    "\n",
    "                    # Collect utterances, speakers, mentions\n",
    "                    temp_sentences.append(utt_sentences)\n",
    "                    temp_answers.extend(utt_answers)\n",
    "                    temp_speakers.append(utt_speaker)\n",
    "\n",
    "                # Build Cluster\n",
    "                cluster_dict = {}\n",
    "                for sent_id, start, end, name in temp_answers:\n",
    "                    if name not in cluster_dict:\n",
    "                        cluster_dict[name] = [(sent_id, start, end)]\n",
    "                    else:\n",
    "                        cluster_dict[name].append((sent_id, start, end))\n",
    "\n",
    "                clusters = []\n",
    "                for item in cluster_dict:\n",
    "                    clusters.append(cluster_dict[item])\n",
    "                # print(scene_id)\n",
    "                # print(\"\".join(scene_id.strip().split(\"_\")))\n",
    "                all_data.append({\n",
    "                    \"sentences\": temp_sentences,\n",
    "                    \"speakers\": temp_speakers,\n",
    "                    \"scene_id\": \"\".join(scene_id.strip().split(\"_\")),\n",
    "                    \"clusters\": clusters\n",
    "                })"
   ],
   "metadata": {
    "collapsed": false,
    "pycharm": {
     "name": "#%%\n"
    }
   }
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "3107 1301\n"
     ]
    }
   ],
   "source": [
    "cleaned_data = []\n",
    "for item in all_data:\n",
    "    if item['speakers']==[]:\n",
    "        continue\n",
    "    cleaned_data.append(item)\n",
    "print(len(all_data), len(cleaned_data))"
   ],
   "metadata": {
    "collapsed": false,
    "pycharm": {
     "name": "#%%\n"
    }
   }
  },
  {
   "cell_type": "code",
   "execution_count": 5,
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "sentences\n",
      "[['There', \"'s\", 'nothing', 'to', 'tell', '!', 'He', \"'s\", 'just', 'some', 'guy', 'I', 'work', 'with', '!'], [\"C'mon\", ',', 'you', \"'re\", 'going', 'out', 'with', 'the', 'guy', '!', 'There', \"'s\", 'got', 'ta', 'be', 'something', 'wrong', 'with', 'him', '!'], ['All', 'right', 'Joey', ',', 'be', 'nice', '.', 'So', 'does', 'he', 'have', 'a', 'hump', '?', 'A', 'hump', 'and', 'a', 'hairpiece', '?'], ['Wait', ',', 'does', 'he', 'eat', 'chalk', '?'], ['Just', ',', \"'\", 'cause', ',', 'I', 'do', \"n't\", 'want', 'her', 'to', 'go', 'through', 'what', 'I', 'went', 'through', 'with', 'Carl', '-', 'oh', '!'], ['Okay', ',', 'everybody', 'relax', '.', 'This', 'is', 'not', 'even', 'a', 'date', '.', 'It', \"'s\", 'just', 'two', 'people', 'going', 'out', 'to', 'dinner', 'and', '-', 'not', 'having', 'sex', '.'], ['Sounds', 'like', 'a', 'date', 'to', 'me', '.'], ['Alright', ',', 'so', 'I', \"'m\", 'back', 'in', 'high', 'school', ',', 'I', \"'m\", 'standing', 'in', 'the', 'middle', 'of', 'the', 'cafeteria', ',', 'and', 'I', 'realize', 'I', 'am', 'totally', 'naked', '.'], ['Oh', ',', 'yeah', '.', 'Had', 'that', 'dream', '.'], ['Then', 'I', 'look', 'down', ',', 'and', 'I', 'realize', 'there', \"'s\", 'a', 'phone', '...', 'there', '.'], ['Instead', 'of', '...?'], ['That', \"'s\", 'right', '.'], ['Never', 'had', 'that', 'dream', '.'], ['No', '.'], ['All', 'of', 'a', 'sudden', ',', 'the', 'phone', 'starts', 'to', 'ring', '.', 'Now', 'I', 'do', \"n't\", 'know', 'what', 'to', 'do', ',', 'everybody', 'starts', 'looking', 'at', 'me', '.'], ['And', 'they', 'were', \"n't\", 'looking', 'at', 'you', 'before', '?!'], ['Finally', ',', 'I', 'figure', 'I', \"'d\", 'better', 'answer', 'it', ',', 'and', 'it', 'turns', 'out', 'it', \"'s\", 'my', 'mother', ',', 'which', 'is', 'very', '-', 'very', 'weird', ',', 'because', '-', 'she', 'never', 'calls', 'me', '!'], ['Hi', '.'], ['This', 'guy', 'says', 'hello', ',', 'I', 'wan', 'na', 'kill', 'myself', '.'], ['Are', 'you', 'okay', ',', 'sweetie', '?'], ['I', 'just', 'feel', 'like', 'someone', 'reached', 'down', 'my', 'throat', ',', 'grabbed', 'my', 'small', 'intestine', ',', 'pulled', 'it', 'out', 'of', 'my', 'mouth', 'and', 'tied', 'it', 'around', 'my', 'neck', '...'], ['Cookie', '?'], ['Carol', 'moved', 'her', 'stuff', 'out', 'today', '.'], ['Ohh', '.'], ['Let', 'me', 'get', 'you', 'some', 'coffee', '.'], ['Thanks', '.'], ['Ooh', '!', 'Oh', '!'], ['No', ',', 'no', 'do', \"n't\", '!', 'Stop', 'cleansing', 'my', 'aura', '!', 'No', ',', 'just', 'leave', 'my', 'aura', 'alone', ',', 'okay', '?'], ['Fine', '!', 'Be', 'murky', '!'], ['I', \"'ll\", 'be', 'fine', ',', 'alright', '?', 'Really', ',', 'everyone', '.', 'I', 'hope', 'she', \"'ll\", 'be', 'very', 'happy', '.'], ['No', 'you', 'do', \"n't\", '.'], ['No', 'I', 'do', \"n't\", ',', 'to', 'hell', 'with', 'her', ',', 'she', 'left', 'me', '!'], ['And', 'you', 'never', 'knew', 'she', 'was', 'a', 'lesbian', '...'], ['No', '!!', 'Okay', '?!', 'Why', 'does', 'everyone', 'keep', 'fixating', 'on', 'that', '?', 'She', 'did', \"n't\", 'know', ',', 'how', 'should', 'I', 'know', '?'], ['Sometimes', 'I', 'wish', 'I', 'was', 'a', 'lesbian', '...', 'Did', 'I', 'say', 'that', 'out', 'loud', '?'], ['I', 'told', 'mom', 'and', 'dad', 'last', 'night', ',', 'they', 'seemed', 'to', 'take', 'it', 'pretty', 'well', '.'], ['Oh', 'really', ',', 'so', 'that', 'hysterical', 'phone', 'call', 'I', 'got', 'from', 'a', 'woman', 'at', 'sobbing', '3:00', 'A.M.', ',', '\"', 'I', \"'ll\", 'never', 'have', 'grandchildren', ',', 'I', \"'ll\", 'never', 'have', 'grandchildren', '.', '\"', 'was', 'what', '?', 'A', 'wrong', 'number', '?'], ['Sorry', '.'], ['Alright', 'Ross', ',', 'look', '.', 'You', \"'re\", 'feeling', 'a', 'lot', 'of', 'pain', 'right', 'now', '.', 'You', \"'re\", 'angry', '.', 'You', \"'re\", 'hurting', '.', 'Can', 'I', 'tell', 'you', 'what', 'the', 'answer', 'is', '?'], ['Strip', 'joint', '!', \"C'mon\", ',', 'you', \"'re\", 'single', '!', 'Have', 'some', 'hormones', '!'], ['I', 'do', \"n't\", 'want', 'to', 'be', 'single', ',', 'okay', '?', 'I', 'just', '...', 'I', 'just', '-', 'I', 'just', 'wan', 'na', 'be', 'married', 'again', '!'], ['And', 'I', 'just', 'want', 'a', 'million', 'dollars', '!'], ['Rachel', '?!'], ['Oh', 'God', 'Monica', 'hi', '!', 'Thank', 'God', '!', 'I', 'just', 'went', 'to', 'your', 'building', 'and', 'you', 'were', \"n't\", 'there', 'and', 'then', 'this', 'guy', 'with', 'a', 'big', 'hammer', 'said', 'you', 'might', 'be', 'here', 'and', 'you', 'are', ',', 'you', 'are', '!'], ['Can', 'I', 'get', 'you', 'some', 'coffee', '?'], ['De-caff', '.', 'Okay', ',', 'everybody', ',', 'this', 'is', 'Rachel', ',', 'another', 'Lincoln', 'High', 'survivor', '.', 'This', 'is', 'everybody', ',', 'this', 'is', 'Chandler', ',', 'and', 'Phoebe', ',', 'and', 'Joey', ',', 'and', '-', 'you', 'remember', 'my', 'brother', 'Ross', '?'], ['Hi', ',', 'sure', '!'], ['Hi', '.'], ['So', 'you', 'wan', 'na', 'tell', 'us', 'now', ',', 'or', 'are', 'we', 'waiting', 'for', 'four', 'wet', 'bridesmaids', '?'], ['Oh', 'God', '...', 'well', ',', 'it', 'started', 'about', 'a', 'half', 'hour', 'before', 'the', 'wedding', '.', 'I', 'was', 'in', 'the', 'room', 'where', 'we', 'were', 'keeping', 'all', 'the', 'presents', ',', 'and', 'I', 'was', 'looking', 'at', 'this', 'gravy', 'boat', '.', 'This', 'really', 'gorgeous', 'Lamauge', 'gravy', 'boat', '.', 'When', 'all', 'of', 'a', 'sudden', '-', 'Sweet', \"'\", 'n', \"'\", 'Lo', '?', '-', 'I', 'realized', 'that', 'I', 'was', 'more', 'turned', 'on', 'by', 'this', 'gravy', 'boat', 'than', 'by', 'Barry', '!', 'And', 'then', 'I', 'got', 'really', 'freaked', 'out', ',', 'and', 'that', \"'s\", 'when', 'it', 'hit', 'me', ':', 'how', 'much', 'Barry', 'looks', 'like', 'Mr.', 'Potato', 'Head', '.', \"Y'know\", ',', 'I', 'mean', ',', 'I', 'always', 'knew', 'looked', 'familiar', ',', 'but', '...', 'Anyway', ',', 'I', 'just', 'had', 'to', 'get', 'out', 'of', 'there', ',', 'and', 'I', 'started', 'wondering', \"'\", 'Why', 'am', 'I', 'doing', 'this', ',', 'and', 'who', 'am', 'I', 'doing', 'this', 'for', '?', \"'\", '.', 'So', 'anyway', 'I', 'just', 'did', \"n't\", 'know', 'where', 'to', 'go', ',', 'and', 'I', 'know', 'that', 'you', 'and', 'I', 'have', 'kinda', 'drifted', 'apart', ',', 'but', 'you', \"'re\", 'the', 'only', 'person', 'I', 'knew', 'who', 'lived', 'here', 'in', 'the', 'city', '.'], ['Who', 'was', \"n't\", 'invited', 'to', 'the', 'wedding', '.'], ['Ooh', ',', 'I', 'was', 'kinda', 'hoping', 'that', 'would', \"n't\", 'be', 'an', 'issue', '...']]\n",
      "\n",
      "speakers\n",
      "['Monica Geller', 'Joey Tribbiani', 'Chandler Bing', 'Phoebe Buffay', 'Phoebe Buffay', 'Monica Geller', 'Chandler Bing', 'Chandler Bing', '#ALL#', 'Chandler Bing', 'Joey Tribbiani', 'Chandler Bing', 'Joey Tribbiani', 'Phoebe Buffay', 'Chandler Bing', 'Monica Geller', 'Chandler Bing', 'Ross Geller', 'Joey Tribbiani', 'Monica Geller', 'Ross Geller', 'Chandler Bing', 'Monica Geller', 'Joey Tribbiani', 'Monica Geller', 'Ross Geller', 'Phoebe Buffay', 'Ross Geller', 'Phoebe Buffay', 'Ross Geller', 'Monica Geller', 'Ross Geller', 'Joey Tribbiani', 'Ross Geller', 'Chandler Bing', 'Ross Geller', 'Monica Geller', 'Ross Geller', 'Joey Tribbiani', 'Joey Tribbiani', 'Ross Geller', 'Chandler Bing', 'Monica Geller', 'Rachel Green', 'Waitress', 'Monica Geller', 'Rachel Green', 'Ross Geller', 'Monica Geller', 'Rachel Green', 'Monica Geller', 'Rachel Green']\n",
      "\n",
      "scene_id\n",
      "s01e01c01\n",
      "\n",
      "clusters\n",
      "[[(0, 6, 7), (0, 10, 11), (1, 8, 9), (1, 18, 19), (2, 9, 10), (3, 3, 4)], [(0, 11, 12), (1, 2, 3), (4, 9, 10), (24, 1, 2), (36, 8, 9), (43, 12, 13), (43, 15, 16), (43, 28, 29), (43, 33, 34), (43, 36, 37), (45, 33, 34), (49, 158, 159), (49, 167, 168), (49, 171, 172)], [(2, 2, 3), (18, 5, 6), (18, 9, 10), (38, 24, 25), (45, 27, 28)], [(4, 5, 6), (4, 14, 15), (45, 24, 25)], [(4, 18, 19)], [(6, 5, 6), (7, 3, 4), (7, 10, 11), (7, 21, 22), (7, 23, 24), (9, 1, 2), (9, 6, 7), (14, 12, 13), (14, 24, 25), (15, 6, 7), (16, 2, 3), (16, 4, 5), (16, 16, 17), (16, 31, 32), (34, 1, 2), (34, 3, 4), (34, 9, 10), (41, 1, 2), (45, 21, 22)], [(15, 1, 2)], [(16, 17, 18), (16, 28, 29)], [(18, 1, 2), (19, 1, 2), (19, 4, 5), (20, 0, 1), (20, 7, 8), (20, 11, 12), (20, 19, 20), (20, 25, 26), (24, 3, 4), (27, 8, 9), (27, 15, 16), (29, 0, 1), (29, 11, 12), (30, 1, 2), (31, 1, 2), (31, 12, 13), (32, 1, 2), (33, 19, 20), (35, 0, 1), (38, 1, 2), (38, 5, 6), (38, 15, 16), (38, 19, 20), (38, 26, 27), (39, 5, 6), (40, 0, 1), (40, 10, 11), (40, 13, 14), (40, 16, 17), (45, 34, 35), (45, 35, 36)], [(22, 0, 1), (22, 2, 3), (29, 13, 14), (31, 8, 9), (31, 10, 11), (32, 4, 5), (33, 12, 13)], [(35, 2, 3), (36, 12, 13), (36, 19, 20), (36, 25, 26)], [(35, 4, 5)], [(35, 8, 9)], [(43, 8, 9), (45, 31, 32), (48, 1, 2), (49, 15, 16), (49, 29, 30), (49, 57, 58), (49, 60, 61), (49, 75, 76), (49, 87, 88), (49, 100, 101), (49, 103, 104), (49, 113, 114), (49, 123, 124), (49, 129, 130), (49, 136, 137), (49, 145, 146), (49, 155, 156), (49, 160, 161), (49, 172, 173), (51, 2, 3)], [(43, 22, 23)], [(44, 1, 2)], [(44, 3, 4)], [(48, 5, 6)], [(48, 10, 11)], [(49, 21, 22)], [(49, 71, 72), (49, 91, 92)]]\n",
      "\n"
     ]
    }
   ],
   "source": [
    "sample = cleaned_data[0]\n",
    "for item in sample:\n",
    "    print(item)\n",
    "    print(sample[item])\n",
    "    print()"
   ],
   "metadata": {
    "collapsed": false,
    "pycharm": {
     "name": "#%%\n"
    }
   }
  },
  {
   "cell_type": "code",
   "execution_count": 6,
   "outputs": [],
   "source": [
    "def flatten_sentences(sentences):\n",
    "    flatten = []\n",
    "    for sent in sentences:\n",
    "        flatten.extend(sent)\n",
    "    return flatten"
   ],
   "metadata": {
    "collapsed": false,
    "pycharm": {
     "name": "#%%\n"
    }
   }
  },
  {
   "cell_type": "code",
   "execution_count": 7,
   "outputs": [
    {
     "ename": "TypeError",
     "evalue": "string indices must be integers",
     "output_type": "error",
     "traceback": [
      "\u001B[0;31m---------------------------------------------------------------------------\u001B[0m",
      "\u001B[0;31mTypeError\u001B[0m                                 Traceback (most recent call last)",
      "\u001B[0;32m/var/folders/w9/673mfrb56v7dvx7hhvw7s6240000gn/T/ipykernel_14505/3250523839.py\u001B[0m in \u001B[0;36m<module>\u001B[0;34m\u001B[0m\n\u001B[1;32m      1\u001B[0m \u001B[0;31m# Check Docuemtn Length\u001B[0m\u001B[0;34m\u001B[0m\u001B[0;34m\u001B[0m\u001B[0;34m\u001B[0m\u001B[0m\n\u001B[1;32m      2\u001B[0m \u001B[0;32mfor\u001B[0m \u001B[0mitem\u001B[0m \u001B[0;32min\u001B[0m \u001B[0mdata\u001B[0m\u001B[0;34m:\u001B[0m\u001B[0;34m\u001B[0m\u001B[0;34m\u001B[0m\u001B[0m\n\u001B[0;32m----> 3\u001B[0;31m     \u001B[0mprint\u001B[0m\u001B[0;34m(\u001B[0m\u001B[0mlen\u001B[0m\u001B[0;34m(\u001B[0m\u001B[0mflatten_sentences\u001B[0m\u001B[0;34m(\u001B[0m\u001B[0mitem\u001B[0m\u001B[0;34m[\u001B[0m\u001B[0;34m'sentences'\u001B[0m\u001B[0;34m]\u001B[0m\u001B[0;34m)\u001B[0m\u001B[0;34m)\u001B[0m\u001B[0;34m)\u001B[0m\u001B[0;34m\u001B[0m\u001B[0;34m\u001B[0m\u001B[0m\n\u001B[0m",
      "\u001B[0;31mTypeError\u001B[0m: string indices must be integers"
     ]
    }
   ],
   "source": [
    "# Check Docuemtn Length\n",
    "for item in data:\n",
    "    print(len(flatten_sentences(item['sentences'])))"
   ],
   "metadata": {
    "collapsed": false,
    "pycharm": {
     "name": "#%%\n"
    }
   }
  },
  {
   "cell_type": "code",
   "execution_count": 8,
   "outputs": [
    {
     "ename": "KeyError",
     "evalue": "0",
     "output_type": "error",
     "traceback": [
      "\u001B[0;31m---------------------------------------------------------------------------\u001B[0m",
      "\u001B[0;31mKeyError\u001B[0m                                  Traceback (most recent call last)",
      "\u001B[0;32m/var/folders/w9/673mfrb56v7dvx7hhvw7s6240000gn/T/ipykernel_14505/1662699794.py\u001B[0m in \u001B[0;36m<module>\u001B[0;34m\u001B[0m\n\u001B[0;32m----> 1\u001B[0;31m \u001B[0mprint\u001B[0m\u001B[0;34m(\u001B[0m\u001B[0mdata\u001B[0m\u001B[0;34m[\u001B[0m\u001B[0;36m0\u001B[0m\u001B[0;34m]\u001B[0m\u001B[0;34m)\u001B[0m\u001B[0;34m\u001B[0m\u001B[0;34m\u001B[0m\u001B[0m\n\u001B[0m",
      "\u001B[0;31mKeyError\u001B[0m: 0"
     ]
    }
   ],
   "source": [
    "print(data[0])"
   ],
   "metadata": {
    "collapsed": false,
    "pycharm": {
     "name": "#%%\n"
    }
   }
  },
  {
   "cell_type": "code",
   "execution_count": 22,
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "1041 130 130\n"
     ]
    }
   ],
   "source": [
    "# Save Data\n",
    "train = cleaned_data[:-260]\n",
    "dev = cleaned_data[-130:]\n",
    "test = cleaned_data[-260:-130]\n",
    "print(len(train), len(dev), len(test))\n",
    "\n",
    "with open('data/raw_source/friends/friends_train.pkl', 'wb') as f:\n",
    "    pkl.dump(train, f)\n",
    "with open('data/raw_source/friends/friends_dev.pkl', 'wb') as f:\n",
    "    pkl.dump(dev, f)\n",
    "with open('data/raw_source/friends/friends_test.pkl', 'wb') as f:\n",
    "    pkl.dump(test, f)"
   ],
   "metadata": {
    "collapsed": false,
    "pycharm": {
     "name": "#%%\n"
    }
   }
  },
  {
   "cell_type": "markdown",
   "source": [
    "## Prepare Friends Data"
   ],
   "metadata": {
    "collapsed": false,
    "pycharm": {
     "name": "#%% md\n"
    }
   }
  },
  {
   "cell_type": "code",
   "execution_count": 11,
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "35082\n"
     ]
    }
   ],
   "source": [
    "file_name = \"test\"\n",
    "\n",
    "with open('data/raw_source/friends/friends_'+file_name+\".pkl\", 'rb') as f:\n",
    "    data = pkl.load(f)\n",
    "\n",
    "document = []\n",
    "for i in range(len(data)):\n",
    "    # if i>=10:\n",
    "    #     continue\n",
    "    sample = data[i]\n",
    "    # Get Data ready for conversion\n",
    "    sentences = sample['sentences']\n",
    "    clusters = sample['clusters']\n",
    "    speakers = sample['speakers']\n",
    "\n",
    "    scene_id = sample['scene_id']\n",
    "    part = int(scene_id[7:9])\n",
    "    begin_line = \"#begin document \" + \"(\" + scene_id + \"); part \" + \"%03d\" % part\n",
    "    end_line = \"#end document\"\n",
    "\n",
    "    # Prepare for clustering\n",
    "    cluster_field = []\n",
    "    for sent in sentences:\n",
    "        cluster_field.append([\"\"]*len(sent))\n",
    "    # Add start\n",
    "    for idx, cluster in enumerate(clusters):\n",
    "        for sent_id, start, end in cluster:\n",
    "            end = end - 1\n",
    "            if start != end:\n",
    "                if cluster_field[sent_id][start] == \"\":\n",
    "                    cluster_field[sent_id][start] += \"(\" + str(idx)\n",
    "                else:\n",
    "                    cluster_field[sent_id][start] += \"|\" + \"(\" + str(idx)\n",
    "    # Add start==end\n",
    "    for idx, cluster in enumerate(clusters):\n",
    "        for sent_id, start, end in cluster:\n",
    "            end = end - 1\n",
    "            if start == end:\n",
    "                if cluster_field[sent_id][start] == \"\":\n",
    "                    cluster_field[sent_id][start] += \"(\" + str(idx) + \")\"\n",
    "                else:\n",
    "                    cluster_field[sent_id][start] += \"|\" + \"(\" + str(idx) + \")\"\n",
    "    # Add End\n",
    "    for idx, cluster in enumerate(clusters):\n",
    "        for sent_id, start, end in cluster:\n",
    "            end = end - 1\n",
    "            if start != end:\n",
    "                try:\n",
    "                    if cluster_field[sent_id][end] == \"\":\n",
    "                        cluster_field[sent_id][end] += str(idx) + \")\"\n",
    "                    else:\n",
    "                        cluster_field[sent_id][end] += \"|\" + str(idx) + \")\"\n",
    "                except:\n",
    "                    pass\n",
    "                # if cluster_field[sent_id][end] == \"\":\n",
    "                #     cluster_field[sent_id][end] += str(idx) + \")\"\n",
    "                # else:\n",
    "                #     cluster_field[sent_id][end] += \"|\" + str(idx) + \")\"\n",
    "\n",
    "    # Build document\n",
    "    document.append(begin_line + \"\\n\")\n",
    "    for sent, speaker, cluster_value in zip(sentences, speakers, cluster_field):\n",
    "        for j, word in enumerate(sent):\n",
    "            cluster_id = cluster_value[j]\n",
    "            if cluster_id == \"\":\n",
    "                cluster_id = \"-\"\n",
    "            temp = [scene_id, str(part), str(j), word, \"na\", \"na\", \"na\", \"na\", \"na\", speaker, \"na\", \"na\", \"na\", cluster_id]\n",
    "            document.append(\" \".join(temp)+ \"\\n\")\n",
    "        document.append(\"\" + \"\\n\")\n",
    "    document.append(end_line + \"\\n\")\n",
    "\n",
    "with open(\"data/conll_style/ci_english/\"+ file_name+'.english.v4_gold_conll', 'w') as f:\n",
    "    f.writelines(document)\n",
    "\n",
    "print(len(document))"
   ],
   "metadata": {
    "collapsed": false,
    "pycharm": {
     "name": "#%%\n"
    }
   }
  },
  {
   "cell_type": "code",
   "execution_count": 145,
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "191431\n"
     ]
    }
   ],
   "source": [
    "print(len(document))"
   ],
   "metadata": {
    "collapsed": false,
    "pycharm": {
     "name": "#%%\n"
    }
   }
  },
  {
   "cell_type": "code",
   "execution_count": 136,
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "#begin document (s01e01c01); part 001\n",
      "\n",
      "s01e01c01 1 0 There na na na na na Monica Geller na na na -\n",
      "\n",
      "s01e01c01 1 1 's na na na na na Monica Geller na na na -\n",
      "\n",
      "s01e01c01 1 2 nothing na na na na na Monica Geller na na na -\n",
      "\n",
      "s01e01c01 1 3 to na na na na na Monica Geller na na na -\n",
      "\n",
      "s01e01c01 1 4 tell na na na na na Monica Geller na na na -\n",
      "\n",
      "s01e01c01 1 5 ! na na na na na Monica Geller na na na -\n",
      "\n",
      "s01e01c01 1 6 He na na na na na Monica Geller na na na (0)\n",
      "\n",
      "s01e01c01 1 7 's na na na na na Monica Geller na na na -\n",
      "\n",
      "s01e01c01 1 8 just na na na na na Monica Geller na na na -\n",
      "\n",
      "s01e01c01 1 9 some na na na na na Monica Geller na na na -\n",
      "\n",
      "s01e01c01 1 10 guy na na na na na Monica Geller na na na (0)\n",
      "\n",
      "s01e01c01 1 11 I na na na na na Monica Geller na na na (1)\n",
      "\n",
      "s01e01c01 1 12 work na na na na na Monica Geller na na na -\n",
      "\n",
      "s01e01c01 1 13 with na na na na na Monica Geller na na na -\n",
      "\n",
      "s01e01c01 1 14 ! na na na na na Monica Geller na na na -\n",
      "\n",
      "\n",
      "\n",
      "s01e01c01 1 0 C'mon na na na na na Joey Tribbiani na na na -\n",
      "\n",
      "s01e01c01 1 1 , na na na na na Joey Tribbiani na na na -\n",
      "\n",
      "s01e01c01 1 2 you na na na na na Joey Tribbiani na na na (1)\n",
      "\n",
      "s01e01c01 1 3 're na na na na na Joey Tribbiani na na na -\n",
      "\n",
      "s01e01c01 1 4 going na na na na na Joey Tribbiani na na na -\n",
      "\n",
      "s01e01c01 1 5 out na na na na na Joey Tribbiani na na na -\n",
      "\n",
      "s01e01c01 1 6 with na na na na na Joey Tribbiani na na na -\n",
      "\n",
      "s01e01c01 1 7 the na na na na na Joey Tribbiani na na na -\n",
      "\n",
      "s01e01c01 1 8 guy na na na na na Joey Tribbiani na na na (0)\n",
      "\n",
      "s01e01c01 1 9 ! na na na na na Joey Tribbiani na na na -\n",
      "\n",
      "s01e01c01 1 10 There na na na na na Joey Tribbiani na na na -\n",
      "\n",
      "s01e01c01 1 11 's na na na na na Joey Tribbiani na na na -\n",
      "\n",
      "s01e01c01 1 12 got na na na na na Joey Tribbiani na na na -\n",
      "\n",
      "s01e01c01 1 13 ta na na na na na Joey Tribbiani na na na -\n",
      "\n",
      "s01e01c01 1 14 be na na na na na Joey Tribbiani na na na -\n",
      "\n",
      "s01e01c01 1 15 something na na na na na Joey Tribbiani na na na -\n",
      "\n",
      "s01e01c01 1 16 wrong na na na na na Joey Tribbiani na na na -\n",
      "\n",
      "s01e01c01 1 17 with na na na na na Joey Tribbiani na na na -\n",
      "\n",
      "s01e01c01 1 18 him na na na na na Joey Tribbiani na na na (0)\n",
      "\n",
      "s01e01c01 1 19 ! na na na na na Joey Tribbiani na na na -\n",
      "\n",
      "\n",
      "\n",
      "s01e01c01 1 0 All na na na na na Chandler Bing na na na -\n",
      "\n",
      "s01e01c01 1 1 right na na na na na Chandler Bing na na na -\n",
      "\n",
      "s01e01c01 1 2 Joey na na na na na Chandler Bing na na na (2)\n",
      "\n",
      "s01e01c01 1 3 , na na na na na Chandler Bing na na na -\n",
      "\n",
      "s01e01c01 1 4 be na na na na na Chandler Bing na na na -\n",
      "\n",
      "s01e01c01 1 5 nice na na na na na Chandler Bing na na na -\n",
      "\n",
      "s01e01c01 1 6 . na na na na na Chandler Bing na na na -\n",
      "\n",
      "s01e01c01 1 7 So na na na na na Chandler Bing na na na -\n",
      "\n",
      "s01e01c01 1 8 does na na na na na Chandler Bing na na na -\n",
      "\n",
      "s01e01c01 1 9 he na na na na na Chandler Bing na na na (0)\n",
      "\n",
      "s01e01c01 1 10 have na na na na na Chandler Bing na na na -\n",
      "\n",
      "s01e01c01 1 11 a na na na na na Chandler Bing na na na -\n",
      "\n",
      "s01e01c01 1 12 hump na na na na na Chandler Bing na na na -\n",
      "\n",
      "s01e01c01 1 13 ? na na na na na Chandler Bing na na na -\n",
      "\n",
      "s01e01c01 1 14 A na na na na na Chandler Bing na na na -\n",
      "\n",
      "s01e01c01 1 15 hump na na na na na Chandler Bing na na na -\n",
      "\n",
      "s01e01c01 1 16 and na na na na na Chandler Bing na na na -\n",
      "\n",
      "s01e01c01 1 17 a na na na na na Chandler Bing na na na -\n",
      "\n",
      "s01e01c01 1 18 hairpiece na na na na na Chandler Bing na na na -\n",
      "\n",
      "s01e01c01 1 19 ? na na na na na Chandler Bing na na na -\n",
      "\n",
      "\n",
      "\n",
      "s01e01c01 1 0 Wait na na na na na Phoebe Buffay na na na -\n",
      "\n",
      "s01e01c01 1 1 , na na na na na Phoebe Buffay na na na -\n",
      "\n",
      "s01e01c01 1 2 does na na na na na Phoebe Buffay na na na -\n",
      "\n",
      "s01e01c01 1 3 he na na na na na Phoebe Buffay na na na (0)\n",
      "\n",
      "s01e01c01 1 4 eat na na na na na Phoebe Buffay na na na -\n",
      "\n",
      "s01e01c01 1 5 chalk na na na na na Phoebe Buffay na na na -\n",
      "\n",
      "s01e01c01 1 6 ? na na na na na Phoebe Buffay na na na -\n",
      "\n",
      "\n",
      "\n",
      "s01e01c01 1 0 Just na na na na na Phoebe Buffay na na na -\n",
      "\n",
      "s01e01c01 1 1 , na na na na na Phoebe Buffay na na na -\n",
      "\n",
      "s01e01c01 1 2 ' na na na na na Phoebe Buffay na na na -\n",
      "\n",
      "s01e01c01 1 3 cause na na na na na Phoebe Buffay na na na -\n",
      "\n",
      "s01e01c01 1 4 , na na na na na Phoebe Buffay na na na -\n",
      "\n",
      "s01e01c01 1 5 I na na na na na Phoebe Buffay na na na (3)\n",
      "\n",
      "s01e01c01 1 6 do na na na na na Phoebe Buffay na na na -\n",
      "\n",
      "s01e01c01 1 7 n't na na na na na Phoebe Buffay na na na -\n",
      "\n",
      "s01e01c01 1 8 want na na na na na Phoebe Buffay na na na -\n",
      "\n",
      "s01e01c01 1 9 her na na na na na Phoebe Buffay na na na (1)\n",
      "\n",
      "s01e01c01 1 10 to na na na na na Phoebe Buffay na na na -\n",
      "\n",
      "s01e01c01 1 11 go na na na na na Phoebe Buffay na na na -\n",
      "\n",
      "s01e01c01 1 12 through na na na na na Phoebe Buffay na na na -\n",
      "\n",
      "s01e01c01 1 13 what na na na na na Phoebe Buffay na na na -\n",
      "\n",
      "s01e01c01 1 14 I na na na na na Phoebe Buffay na na na (3)\n",
      "\n",
      "s01e01c01 1 15 went na na na na na Phoebe Buffay na na na -\n",
      "\n",
      "s01e01c01 1 16 through na na na na na Phoebe Buffay na na na -\n",
      "\n",
      "s01e01c01 1 17 with na na na na na Phoebe Buffay na na na -\n",
      "\n",
      "s01e01c01 1 18 Carl na na na na na Phoebe Buffay na na na (4)\n",
      "\n",
      "s01e01c01 1 19 - na na na na na Phoebe Buffay na na na -\n",
      "\n",
      "s01e01c01 1 20 oh na na na na na Phoebe Buffay na na na -\n",
      "\n",
      "s01e01c01 1 21 ! na na na na na Phoebe Buffay na na na -\n",
      "\n",
      "\n",
      "\n",
      "s01e01c01 1 0 Okay na na na na na Monica Geller na na na -\n",
      "\n",
      "s01e01c01 1 1 , na na na na na Monica Geller na na na -\n",
      "\n",
      "s01e01c01 1 2 everybody na na na na na Monica Geller na na na -\n",
      "\n",
      "s01e01c01 1 3 relax na na na na na Monica Geller na na na -\n",
      "\n",
      "s01e01c01 1 4 . na na na na na Monica Geller na na na -\n",
      "\n",
      "s01e01c01 1 5 This na na na na na Monica Geller na na na -\n",
      "\n",
      "s01e01c01 1 6 is na na na na na Monica Geller na na na -\n",
      "\n",
      "s01e01c01 1 7 not na na na na na Monica Geller na na na -\n",
      "\n",
      "s01e01c01 1 8 even na na na na na Monica Geller na na na -\n",
      "\n",
      "s01e01c01 1 9 a na na na na na Monica Geller na na na -\n",
      "\n",
      "s01e01c01 1 10 date na na na na na Monica Geller na na na -\n",
      "\n",
      "s01e01c01 1 11 . na na na na na Monica Geller na na na -\n",
      "\n",
      "s01e01c01 1 12 It na na na na na Monica Geller na na na -\n",
      "\n",
      "s01e01c01 1 13 's na na na na na Monica Geller na na na -\n",
      "\n",
      "s01e01c01 1 14 just na na na na na Monica Geller na na na -\n",
      "\n",
      "s01e01c01 1 15 two na na na na na Monica Geller na na na -\n",
      "\n",
      "s01e01c01 1 16 people na na na na na Monica Geller na na na -\n",
      "\n",
      "s01e01c01 1 17 going na na na na na Monica Geller na na na -\n",
      "\n",
      "s01e01c01 1 18 out na na na na na Monica Geller na na na -\n",
      "\n",
      "s01e01c01 1 19 to na na na na na Monica Geller na na na -\n",
      "\n",
      "s01e01c01 1 20 dinner na na na na na Monica Geller na na na -\n",
      "\n",
      "s01e01c01 1 21 and na na na na na Monica Geller na na na -\n",
      "\n",
      "s01e01c01 1 22 - na na na na na Monica Geller na na na -\n",
      "\n",
      "s01e01c01 1 23 not na na na na na Monica Geller na na na -\n",
      "\n",
      "s01e01c01 1 24 having na na na na na Monica Geller na na na -\n",
      "\n",
      "s01e01c01 1 25 sex na na na na na Monica Geller na na na -\n",
      "\n",
      "s01e01c01 1 26 . na na na na na Monica Geller na na na -\n",
      "\n",
      "\n",
      "\n",
      "s01e01c01 1 0 Sounds na na na na na Chandler Bing na na na -\n",
      "\n",
      "s01e01c01 1 1 like na na na na na Chandler Bing na na na -\n",
      "\n",
      "s01e01c01 1 2 a na na na na na Chandler Bing na na na -\n",
      "\n",
      "s01e01c01 1 3 date na na na na na Chandler Bing na na na -\n",
      "\n",
      "s01e01c01 1 4 to na na na na na Chandler Bing na na na -\n",
      "\n",
      "s01e01c01 1 5 me na na na na na Chandler Bing na na na (5)\n",
      "\n",
      "s01e01c01 1 6 . na na na na na Chandler Bing na na na -\n",
      "\n",
      "\n",
      "\n",
      "s01e01c01 1 0 Alright na na na na na Chandler Bing na na na -\n",
      "\n",
      "s01e01c01 1 1 , na na na na na Chandler Bing na na na -\n",
      "\n",
      "s01e01c01 1 2 so na na na na na Chandler Bing na na na -\n",
      "\n",
      "s01e01c01 1 3 I na na na na na Chandler Bing na na na (5)\n",
      "\n",
      "s01e01c01 1 4 'm na na na na na Chandler Bing na na na -\n",
      "\n",
      "s01e01c01 1 5 back na na na na na Chandler Bing na na na -\n",
      "\n",
      "s01e01c01 1 6 in na na na na na Chandler Bing na na na -\n",
      "\n",
      "s01e01c01 1 7 high na na na na na Chandler Bing na na na -\n",
      "\n",
      "s01e01c01 1 8 school na na na na na Chandler Bing na na na -\n",
      "\n",
      "s01e01c01 1 9 , na na na na na Chandler Bing na na na -\n",
      "\n",
      "s01e01c01 1 10 I na na na na na Chandler Bing na na na (5)\n",
      "\n",
      "s01e01c01 1 11 'm na na na na na Chandler Bing na na na -\n",
      "\n",
      "s01e01c01 1 12 standing na na na na na Chandler Bing na na na -\n",
      "\n",
      "s01e01c01 1 13 in na na na na na Chandler Bing na na na -\n",
      "\n",
      "s01e01c01 1 14 the na na na na na Chandler Bing na na na -\n",
      "\n",
      "s01e01c01 1 15 middle na na na na na Chandler Bing na na na -\n",
      "\n",
      "s01e01c01 1 16 of na na na na na Chandler Bing na na na -\n",
      "\n",
      "s01e01c01 1 17 the na na na na na Chandler Bing na na na -\n",
      "\n",
      "s01e01c01 1 18 cafeteria na na na na na Chandler Bing na na na -\n",
      "\n",
      "s01e01c01 1 19 , na na na na na Chandler Bing na na na -\n",
      "\n",
      "s01e01c01 1 20 and na na na na na Chandler Bing na na na -\n",
      "\n",
      "s01e01c01 1 21 I na na na na na Chandler Bing na na na (5)\n",
      "\n",
      "s01e01c01 1 22 realize na na na na na Chandler Bing na na na -\n",
      "\n",
      "s01e01c01 1 23 I na na na na na Chandler Bing na na na (5)\n",
      "\n",
      "s01e01c01 1 24 am na na na na na Chandler Bing na na na -\n",
      "\n",
      "s01e01c01 1 25 totally na na na na na Chandler Bing na na na -\n",
      "\n",
      "s01e01c01 1 26 naked na na na na na Chandler Bing na na na -\n",
      "\n",
      "s01e01c01 1 27 . na na na na na Chandler Bing na na na -\n",
      "\n",
      "\n",
      "\n",
      "s01e01c01 1 0 Oh na na na na na #ALL# na na na -\n",
      "\n",
      "s01e01c01 1 1 , na na na na na #ALL# na na na -\n",
      "\n",
      "s01e01c01 1 2 yeah na na na na na #ALL# na na na -\n",
      "\n",
      "s01e01c01 1 3 . na na na na na #ALL# na na na -\n",
      "\n",
      "s01e01c01 1 4 Had na na na na na #ALL# na na na -\n",
      "\n",
      "s01e01c01 1 5 that na na na na na #ALL# na na na -\n",
      "\n",
      "s01e01c01 1 6 dream na na na na na #ALL# na na na -\n",
      "\n",
      "s01e01c01 1 7 . na na na na na #ALL# na na na -\n",
      "\n",
      "\n",
      "\n",
      "s01e01c01 1 0 Then na na na na na Chandler Bing na na na -\n",
      "\n",
      "s01e01c01 1 1 I na na na na na Chandler Bing na na na (5)\n",
      "\n",
      "s01e01c01 1 2 look na na na na na Chandler Bing na na na -\n",
      "\n",
      "s01e01c01 1 3 down na na na na na Chandler Bing na na na -\n",
      "\n",
      "s01e01c01 1 4 , na na na na na Chandler Bing na na na -\n",
      "\n",
      "s01e01c01 1 5 and na na na na na Chandler Bing na na na -\n",
      "\n",
      "s01e01c01 1 6 I na na na na na Chandler Bing na na na (5)\n",
      "\n",
      "s01e01c01 1 7 realize na na na na na Chandler Bing na na na -\n",
      "\n",
      "s01e01c01 1 8 there na na na na na Chandler Bing na na na -\n",
      "\n",
      "s01e01c01 1 9 's na na na na na Chandler Bing na na na -\n",
      "\n",
      "s01e01c01 1 10 a na na na na na Chandler Bing na na na -\n",
      "\n",
      "s01e01c01 1 11 phone na na na na na Chandler Bing na na na -\n",
      "\n",
      "s01e01c01 1 12 ... na na na na na Chandler Bing na na na -\n",
      "\n",
      "s01e01c01 1 13 there na na na na na Chandler Bing na na na -\n",
      "\n",
      "s01e01c01 1 14 . na na na na na Chandler Bing na na na -\n",
      "\n",
      "\n",
      "\n",
      "s01e01c01 1 0 Instead na na na na na Joey Tribbiani na na na -\n",
      "\n",
      "s01e01c01 1 1 of na na na na na Joey Tribbiani na na na -\n",
      "\n",
      "s01e01c01 1 2 ...? na na na na na Joey Tribbiani na na na -\n",
      "\n",
      "\n",
      "\n",
      "s01e01c01 1 0 That na na na na na Chandler Bing na na na -\n",
      "\n",
      "s01e01c01 1 1 's na na na na na Chandler Bing na na na -\n",
      "\n",
      "s01e01c01 1 2 right na na na na na Chandler Bing na na na -\n",
      "\n",
      "s01e01c01 1 3 . na na na na na Chandler Bing na na na -\n",
      "\n",
      "\n",
      "\n",
      "s01e01c01 1 0 Never na na na na na Joey Tribbiani na na na -\n",
      "\n",
      "s01e01c01 1 1 had na na na na na Joey Tribbiani na na na -\n",
      "\n",
      "s01e01c01 1 2 that na na na na na Joey Tribbiani na na na -\n",
      "\n",
      "s01e01c01 1 3 dream na na na na na Joey Tribbiani na na na -\n",
      "\n",
      "s01e01c01 1 4 . na na na na na Joey Tribbiani na na na -\n",
      "\n",
      "\n",
      "\n",
      "s01e01c01 1 0 No na na na na na Phoebe Buffay na na na -\n",
      "\n",
      "s01e01c01 1 1 . na na na na na Phoebe Buffay na na na -\n",
      "\n",
      "\n",
      "\n",
      "s01e01c01 1 0 All na na na na na Chandler Bing na na na -\n",
      "\n",
      "s01e01c01 1 1 of na na na na na Chandler Bing na na na -\n",
      "\n"
     ]
    }
   ],
   "source": [
    "for line in document[:200]:\n",
    "    print(line)"
   ],
   "metadata": {
    "collapsed": false,
    "pycharm": {
     "name": "#%%\n"
    }
   }
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "outputs": [],
   "source": [],
   "metadata": {
    "collapsed": false,
    "pycharm": {
     "name": "#%%\n"
    }
   }
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "outputs": [],
   "source": [],
   "metadata": {
    "collapsed": false,
    "pycharm": {
     "name": "#%%\n"
    }
   }
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "outputs": [],
   "source": [],
   "metadata": {
    "collapsed": false,
    "pycharm": {
     "name": "#%%\n"
    }
   }
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "outputs": [],
   "source": [],
   "metadata": {
    "collapsed": false,
    "pycharm": {
     "name": "#%%\n"
    }
   }
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "outputs": [],
   "source": [],
   "metadata": {
    "collapsed": false,
    "pycharm": {
     "name": "#%%\n"
    }
   }
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "outputs": [],
   "source": [],
   "metadata": {
    "collapsed": false,
    "pycharm": {
     "name": "#%%\n"
    }
   }
  },
  {
   "cell_type": "markdown",
   "source": [
    "## Prepare Friends Dataset"
   ],
   "metadata": {
    "collapsed": false,
    "pycharm": {
     "name": "#%% md\n"
    }
   }
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "outputs": [],
   "source": [],
   "metadata": {
    "collapsed": false,
    "pycharm": {
     "name": "#%%\n"
    }
   }
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "outputs": [],
   "source": [],
   "metadata": {
    "collapsed": false,
    "pycharm": {
     "name": "#%%\n"
    }
   }
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "outputs": [],
   "source": [
    "file_name = \"test\"\n",
    "data = []\n",
    "with open('data/'+ file_name+'_temp.pkl', 'rb') as f:\n",
    "    data.extend(pkl.load(f))\n",
    "\n",
    "document = []\n",
    "for i in range(len(data)):\n",
    "    if file_name==\"train\" and i==38:\n",
    "        continue\n",
    "    if file_name==\"test\" and i==28:\n",
    "        continue\n",
    "\n",
    "    # if i>=100:\n",
    "    #     continue\n",
    "    sample = data[i]\n",
    "    original_sentences = sample['sentences']\n",
    "    original_clusters = cluster_mentions(sample['answers'], original_sentences)\n",
    "\n",
    "    # Get Data ready for conversion\n",
    "    sentences, clusters, speakers = remove_speaker_prefix(original_sentences, original_clusters)\n",
    "    scene_id = sample['scene_id']\n",
    "    part = int(scene_id[7:9])\n",
    "    begin_line = \"#begin document \" + \"(\" + scene_id + \"); part \" + \"%03d\" % part\n",
    "    end_line = \"#end document\"\n",
    "\n",
    "    # Prepare for clustering\n",
    "    cluster_field = []\n",
    "    for sent in sentences:\n",
    "        cluster_field.append([\"\"]*len(sent))\n",
    "    # Add start\n",
    "    for idx, cluster in enumerate(clusters):\n",
    "        for sent_id, start, end in cluster:\n",
    "            end = end - 1\n",
    "            if start != end:\n",
    "                if cluster_field[sent_id][start] == \"\":\n",
    "                    cluster_field[sent_id][start] += \"(\" + str(idx)\n",
    "                else:\n",
    "                    cluster_field[sent_id][start] += \"|\" + \"(\" + str(idx)\n",
    "    # Add start==end\n",
    "    for idx, cluster in enumerate(clusters):\n",
    "        for sent_id, start, end in cluster:\n",
    "            end = end - 1\n",
    "            if start == end:\n",
    "                if cluster_field[sent_id][start] == \"\":\n",
    "                    cluster_field[sent_id][start] += \"(\" + str(idx) + \")\"\n",
    "                else:\n",
    "                    cluster_field[sent_id][start] += \"|\" + \"(\" + str(idx) + \")\"\n",
    "    # Add End\n",
    "    for idx, cluster in enumerate(clusters):\n",
    "        for sent_id, start, end in cluster:\n",
    "            end = end - 1\n",
    "            if start != end:\n",
    "                try:\n",
    "                    if cluster_field[sent_id][end] == \"\":\n",
    "                        cluster_field[sent_id][end] += str(idx) + \")\"\n",
    "                    else:\n",
    "                        cluster_field[sent_id][end] += \"|\" + str(idx) + \")\"\n",
    "                except:\n",
    "                    pass\n",
    "                # if cluster_field[sent_id][end] == \"\":\n",
    "                #     cluster_field[sent_id][end] += str(idx) + \")\"\n",
    "                # else:\n",
    "                #     cluster_field[sent_id][end] += \"|\" + str(idx) + \")\"\n",
    "\n",
    "    # Build document\n",
    "    document.append(begin_line + \"\\n\")\n",
    "    for sent, speaker, cluster_value in zip(sentences, speakers, cluster_field):\n",
    "        for j, word in enumerate(sent):\n",
    "            cluster_id = cluster_value[j]\n",
    "            if cluster_id == \"\":\n",
    "                cluster_id = \"-\"\n",
    "            temp = [scene_id, str(part), str(j), word, \"na\", \"na\", \"na\", \"na\", \"na\", speaker, \"na\", \"na\", \"na\", cluster_id]\n",
    "            document.append(\" \".join(temp)+ \"\\n\")\n",
    "        document.append(\"\" + \"\\n\")\n",
    "    document.append(end_line + \"\\n\")\n",
    "\n",
    "with open(\"data/input/\"+ file_name+'.english.v4_gold_conll', 'w') as f:\n",
    "    f.writelines(document)"
   ],
   "metadata": {
    "collapsed": false,
    "pycharm": {
     "name": "#%%\n"
    }
   }
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "outputs": [],
   "source": [],
   "metadata": {
    "collapsed": false,
    "pycharm": {
     "name": "#%%\n"
    }
   }
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "outputs": [],
   "source": [],
   "metadata": {
    "collapsed": false,
    "pycharm": {
     "name": "#%%\n"
    }
   }
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "outputs": [],
   "source": [],
   "metadata": {
    "collapsed": false,
    "pycharm": {
     "name": "#%%\n"
    }
   }
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "outputs": [],
   "source": [],
   "metadata": {
    "collapsed": false,
    "pycharm": {
     "name": "#%%\n"
    }
   }
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "outputs": [],
   "source": [],
   "metadata": {
    "collapsed": false,
    "pycharm": {
     "name": "#%%\n"
    }
   }
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "outputs": [],
   "source": [],
   "metadata": {
    "collapsed": false,
    "pycharm": {
     "name": "#%%\n"
    }
   }
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "outputs": [],
   "source": [],
   "metadata": {
    "collapsed": false,
    "pycharm": {
     "name": "#%%\n"
    }
   }
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "outputs": [],
   "source": [],
   "metadata": {
    "collapsed": false,
    "pycharm": {
     "name": "#%%\n"
    }
   }
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "outputs": [],
   "source": [],
   "metadata": {
    "collapsed": false,
    "pycharm": {
     "name": "#%%\n"
    }
   }
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "outputs": [],
   "source": [],
   "metadata": {
    "collapsed": false,
    "pycharm": {
     "name": "#%%\n"
    }
   }
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "outputs": [],
   "source": [],
   "metadata": {
    "collapsed": false,
    "pycharm": {
     "name": "#%%\n"
    }
   }
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "outputs": [],
   "source": [],
   "metadata": {
    "collapsed": false,
    "pycharm": {
     "name": "#%%\n"
    }
   }
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 2
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython2",
   "version": "2.7.6"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 0
}